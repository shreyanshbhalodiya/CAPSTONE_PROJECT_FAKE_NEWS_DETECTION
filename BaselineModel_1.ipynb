{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "BaselineModel-1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1p4lZVy2iLb"
      },
      "source": [
        "#**Experiment-3**\n",
        "\n",
        "**AIM**: To construct a Machine learning model for 2-class prediction(related and unrelated) and to reduce the misclassification rate.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWzM9Pa72c5x"
      },
      "source": [
        "# importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JetUCQCb2c5y"
      },
      "source": [
        "train = pd.read_csv(r\"C:\\Users\\Shreyansh\\Capstone_files\\final_train_data.csv\") # train dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iY7cunb2c5z"
      },
      "source": [
        "test = pd.read_csv(r\"C:\\Users\\Shreyansh\\Capstone_files\\final_test_data.csv\")  # test dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boEJHa592c5z",
        "outputId": "0bc996a9-6caf-429c-d66f-1817fa885dbe"
      },
      "source": [
        "train.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'Unnamed: 0.1', 'Headline', 'Body ID', 'articleBody',\n",
              "       'jaccard_similarity', 'Headline_Nouns', 'articleBody_Nouns',\n",
              "       'jaccard_similarity_nouns', 'Headline_POS', 'articleBody_POS', 'Stance',\n",
              "       'glove_similarity', 'kl_divergence', 'ngram_overlap',\n",
              "       'semantic_similarity', 'stance_base', 'LDA_Score'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "d8m3IpQ82c51",
        "outputId": "8eb1b39c-5a6f-435d-b1ff-bc2d1c00bf10"
      },
      "source": [
        "test.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'Headline', 'Stance', 'articleBody', 'stance_cat',\n",
              "       'jaccard_similarity', 'Headline_pos', 'articleBody_pos',\n",
              "       'jaccard_similarity_nouns', 'Headline_Nouns',\n",
              "       'articleBody_pos_lemmatized', 'Headline_pos_lemmatized', 'LDA_Score',\n",
              "       'glove_similarity', 'kl_divergence', 'ngram_overlap',\n",
              "       'semantic_similarity', 'stance_base'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "k87ZEoPO2c51"
      },
      "source": [
        "test2 = test[['Headline', 'Stance',\"articleBody\"]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8ZwaS3I2c52"
      },
      "source": [
        "test_reslults = test2.groupby(['Headline','Stance']).count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cf593QOu2c52",
        "outputId": "a76ddba8-8408-4377-daab-335ddf77a6f1"
      },
      "source": [
        "test_reslults[:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>articleBody</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Headline</th>\n",
              "      <th>Stance</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>ab de villiers wife danielle welcomed newborn daughter yente family</th>\n",
              "      <th>agree</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>actor commits suicide actress tragic social sameer mental health come rs committed bhojpuri work wouldepression</th>\n",
              "      <th>unrelated</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bitcoin tops wins mainstream acceptance</th>\n",
              "      <th>agree</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                              articleBody\n",
              "Headline                                           Stance                \n",
              "ab de villiers wife danielle welcomed newborn d... agree                7\n",
              "actor commits suicide actress tragic social sam... unrelated            1\n",
              "bitcoin tops wins mainstream acceptance            agree                1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uus7q_rb2c53"
      },
      "source": [
        "test_reslults2 = pd.DataFrame(test_reslults[:3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBMXRYE62c53"
      },
      "source": [
        "test_reslults2 = test_reslults2.reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "eprqpLfy2c53",
        "outputId": "1ff501e0-dcb2-4a24-d980-e7582ee4371d"
      },
      "source": [
        "unrelated = test_reslults2[test_reslults2.Stance == \"agree\"]\n",
        "unrelated"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Headline</th>\n",
              "      <th>Stance</th>\n",
              "      <th>articleBody</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ab de villiers wife danielle welcomed newborn ...</td>\n",
              "      <td>agree</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>bitcoin tops wins mainstream acceptance</td>\n",
              "      <td>agree</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Headline Stance  articleBody\n",
              "0  ab de villiers wife danielle welcomed newborn ...  agree            7\n",
              "2            bitcoin tops wins mainstream acceptance  agree            1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Awl909lQ2c54",
        "outputId": "de14f74a-d87f-4917-944a-909703913b04"
      },
      "source": [
        "unrelated[\"articleBody\"].iloc[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ffimd9c2c54",
        "outputId": "7e891c3f-cac1-4ff3-ae74-fcc02730005d"
      },
      "source": [
        "train[\"stance_base\"].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['unrelated', 'related'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "638IXwY02c55",
        "outputId": "40f078dd-7419-4a84-ac52-dfa7260ca6c9"
      },
      "source": [
        "test[\"stance_base\"].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['related', 'unrelated'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MP8o2yxR2c55",
        "outputId": "06e6e332-adec-4189-f448-090a2048168f"
      },
      "source": [
        "import itertools   # consider 7-features as predictors\n",
        "a = []\n",
        "stuff = ['jaccard_similarity', 'jaccard_similarity_nouns', 'glove_similarity', 'kl_divergence', 'ngram_overlap',\n",
        "         \"semantic_similarity\", \"LDA_Score\"]\n",
        "for L in range(0, len(stuff)+1):\n",
        "    for subset in itertools.combinations(stuff, L):\n",
        "        a.append(list(subset))\n",
        "        \n",
        "print(len(a))\n",
        "#print(a)\n",
        "\n",
        "x_ = a\n",
        "y = len(x_)\n",
        "xyz = x_[-(y-1):]\n",
        "print(xyz)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "128\n",
            "[['jaccard_similarity'], ['jaccard_similarity_nouns'], ['glove_similarity'], ['kl_divergence'], ['ngram_overlap'], ['semantic_similarity'], ['LDA_Score'], ['jaccard_similarity', 'jaccard_similarity_nouns'], ['jaccard_similarity', 'glove_similarity'], ['jaccard_similarity', 'kl_divergence'], ['jaccard_similarity', 'ngram_overlap'], ['jaccard_similarity', 'semantic_similarity'], ['jaccard_similarity', 'LDA_Score'], ['jaccard_similarity_nouns', 'glove_similarity'], ['jaccard_similarity_nouns', 'kl_divergence'], ['jaccard_similarity_nouns', 'ngram_overlap'], ['jaccard_similarity_nouns', 'semantic_similarity'], ['jaccard_similarity_nouns', 'LDA_Score'], ['glove_similarity', 'kl_divergence'], ['glove_similarity', 'ngram_overlap'], ['glove_similarity', 'semantic_similarity'], ['glove_similarity', 'LDA_Score'], ['kl_divergence', 'ngram_overlap'], ['kl_divergence', 'semantic_similarity'], ['kl_divergence', 'LDA_Score'], ['ngram_overlap', 'semantic_similarity'], ['ngram_overlap', 'LDA_Score'], ['semantic_similarity', 'LDA_Score'], ['jaccard_similarity', 'jaccard_similarity_nouns', 'glove_similarity'], ['jaccard_similarity', 'jaccard_similarity_nouns', 'kl_divergence'], ['jaccard_similarity', 'jaccard_similarity_nouns', 'ngram_overlap'], ['jaccard_similarity', 'jaccard_similarity_nouns', 'semantic_similarity'], ['jaccard_similarity', 'jaccard_similarity_nouns', 'LDA_Score'], ['jaccard_similarity', 'glove_similarity', 'kl_divergence'], ['jaccard_similarity', 'glove_similarity', 'ngram_overlap'], ['jaccard_similarity', 'glove_similarity', 'semantic_similarity'], ['jaccard_similarity', 'glove_similarity', 'LDA_Score'], ['jaccard_similarity', 'kl_divergence', 'ngram_overlap'], ['jaccard_similarity', 'kl_divergence', 'semantic_similarity'], ['jaccard_similarity', 'kl_divergence', 'LDA_Score'], ['jaccard_similarity', 'ngram_overlap', 'semantic_similarity'], ['jaccard_similarity', 'ngram_overlap', 'LDA_Score'], ['jaccard_similarity', 'semantic_similarity', 'LDA_Score'], ['jaccard_similarity_nouns', 'glove_similarity', 'kl_divergence'], ['jaccard_similarity_nouns', 'glove_similarity', 'ngram_overlap'], ['jaccard_similarity_nouns', 'glove_similarity', 'semantic_similarity'], ['jaccard_similarity_nouns', 'glove_similarity', 'LDA_Score'], ['jaccard_similarity_nouns', 'kl_divergence', 'ngram_overlap'], ['jaccard_similarity_nouns', 'kl_divergence', 'semantic_similarity'], ['jaccard_similarity_nouns', 'kl_divergence', 'LDA_Score'], ['jaccard_similarity_nouns', 'ngram_overlap', 'semantic_similarity'], ['jaccard_similarity_nouns', 'ngram_overlap', 'LDA_Score'], ['jaccard_similarity_nouns', 'semantic_similarity', 'LDA_Score'], ['glove_similarity', 'kl_divergence', 'ngram_overlap'], ['glove_similarity', 'kl_divergence', 'semantic_similarity'], ['glove_similarity', 'kl_divergence', 'LDA_Score'], ['glove_similarity', 'ngram_overlap', 'semantic_similarity'], ['glove_similarity', 'ngram_overlap', 'LDA_Score'], ['glove_similarity', 'semantic_similarity', 'LDA_Score'], ['kl_divergence', 'ngram_overlap', 'semantic_similarity'], ['kl_divergence', 'ngram_overlap', 'LDA_Score'], ['kl_divergence', 'semantic_similarity', 'LDA_Score'], ['ngram_overlap', 'semantic_similarity', 'LDA_Score'], ['jaccard_similarity', 'jaccard_similarity_nouns', 'glove_similarity', 'kl_divergence'], ['jaccard_similarity', 'jaccard_similarity_nouns', 'glove_similarity', 'ngram_overlap'], ['jaccard_similarity', 'jaccard_similarity_nouns', 'glove_similarity', 'semantic_similarity'], ['jaccard_similarity', 'jaccard_similarity_nouns', 'glove_similarity', 'LDA_Score'], ['jaccard_similarity', 'jaccard_similarity_nouns', 'kl_divergence', 'ngram_overlap'], ['jaccard_similarity', 'jaccard_similarity_nouns', 'kl_divergence', 'semantic_similarity'], ['jaccard_similarity', 'jaccard_similarity_nouns', 'kl_divergence', 'LDA_Score'], ['jaccard_similarity', 'jaccard_similarity_nouns', 'ngram_overlap', 'semantic_similarity'], ['jaccard_similarity', 'jaccard_similarity_nouns', 'ngram_overlap', 'LDA_Score'], ['jaccard_similarity', 'jaccard_similarity_nouns', 'semantic_similarity', 'LDA_Score'], ['jaccard_similarity', 'glove_similarity', 'kl_divergence', 'ngram_overlap'], ['jaccard_similarity', 'glove_similarity', 'kl_divergence', 'semantic_similarity'], ['jaccard_similarity', 'glove_similarity', 'kl_divergence', 'LDA_Score'], ['jaccard_similarity', 'glove_similarity', 'ngram_overlap', 'semantic_similarity'], ['jaccard_similarity', 'glove_similarity', 'ngram_overlap', 'LDA_Score'], ['jaccard_similarity', 'glove_similarity', 'semantic_similarity', 'LDA_Score'], ['jaccard_similarity', 'kl_divergence', 'ngram_overlap', 'semantic_similarity'], ['jaccard_similarity', 'kl_divergence', 'ngram_overlap', 'LDA_Score'], ['jaccard_similarity', 'kl_divergence', 'semantic_similarity', 'LDA_Score'], ['jaccard_similarity', 'ngram_overlap', 'semantic_similarity', 'LDA_Score'], ['jaccard_similarity_nouns', 'glove_similarity', 'kl_divergence', 'ngram_overlap'], ['jaccard_similarity_nouns', 'glove_similarity', 'kl_divergence', 'semantic_similarity'], ['jaccard_similarity_nouns', 'glove_similarity', 'kl_divergence', 'LDA_Score'], ['jaccard_similarity_nouns', 'glove_similarity', 'ngram_overlap', 'semantic_similarity'], ['jaccard_similarity_nouns', 'glove_similarity', 'ngram_overlap', 'LDA_Score'], ['jaccard_similarity_nouns', 'glove_similarity', 'semantic_similarity', 'LDA_Score'], ['jaccard_similarity_nouns', 'kl_divergence', 'ngram_overlap', 'semantic_similarity'], ['jaccard_similarity_nouns', 'kl_divergence', 'ngram_overlap', 'LDA_Score'], ['jaccard_similarity_nouns', 'kl_divergence', 'semantic_similarity', 'LDA_Score'], ['jaccard_similarity_nouns', 'ngram_overlap', 'semantic_similarity', 'LDA_Score'], ['glove_similarity', 'kl_divergence', 'ngram_overlap', 'semantic_similarity'], ['glove_similarity', 'kl_divergence', 'ngram_overlap', 'LDA_Score'], ['glove_similarity', 'kl_divergence', 'semantic_similarity', 'LDA_Score'], ['glove_similarity', 'ngram_overlap', 'semantic_similarity', 'LDA_Score'], ['kl_divergence', 'ngram_overlap', 'semantic_similarity', 'LDA_Score'], ['jaccard_similarity', 'jaccard_similarity_nouns', 'glove_similarity', 'kl_divergence', 'ngram_overlap'], ['jaccard_similarity', 'jaccard_similarity_nouns', 'glove_similarity', 'kl_divergence', 'semantic_similarity'], ['jaccard_similarity', 'jaccard_similarity_nouns', 'glove_similarity', 'kl_divergence', 'LDA_Score'], ['jaccard_similarity', 'jaccard_similarity_nouns', 'glove_similarity', 'ngram_overlap', 'semantic_similarity'], ['jaccard_similarity', 'jaccard_similarity_nouns', 'glove_similarity', 'ngram_overlap', 'LDA_Score'], ['jaccard_similarity', 'jaccard_similarity_nouns', 'glove_similarity', 'semantic_similarity', 'LDA_Score'], ['jaccard_similarity', 'jaccard_similarity_nouns', 'kl_divergence', 'ngram_overlap', 'semantic_similarity'], ['jaccard_similarity', 'jaccard_similarity_nouns', 'kl_divergence', 'ngram_overlap', 'LDA_Score'], ['jaccard_similarity', 'jaccard_similarity_nouns', 'kl_divergence', 'semantic_similarity', 'LDA_Score'], ['jaccard_similarity', 'jaccard_similarity_nouns', 'ngram_overlap', 'semantic_similarity', 'LDA_Score'], ['jaccard_similarity', 'glove_similarity', 'kl_divergence', 'ngram_overlap', 'semantic_similarity'], ['jaccard_similarity', 'glove_similarity', 'kl_divergence', 'ngram_overlap', 'LDA_Score'], ['jaccard_similarity', 'glove_similarity', 'kl_divergence', 'semantic_similarity', 'LDA_Score'], ['jaccard_similarity', 'glove_similarity', 'ngram_overlap', 'semantic_similarity', 'LDA_Score'], ['jaccard_similarity', 'kl_divergence', 'ngram_overlap', 'semantic_similarity', 'LDA_Score'], ['jaccard_similarity_nouns', 'glove_similarity', 'kl_divergence', 'ngram_overlap', 'semantic_similarity'], ['jaccard_similarity_nouns', 'glove_similarity', 'kl_divergence', 'ngram_overlap', 'LDA_Score'], ['jaccard_similarity_nouns', 'glove_similarity', 'kl_divergence', 'semantic_similarity', 'LDA_Score'], ['jaccard_similarity_nouns', 'glove_similarity', 'ngram_overlap', 'semantic_similarity', 'LDA_Score'], ['jaccard_similarity_nouns', 'kl_divergence', 'ngram_overlap', 'semantic_similarity', 'LDA_Score'], ['glove_similarity', 'kl_divergence', 'ngram_overlap', 'semantic_similarity', 'LDA_Score'], ['jaccard_similarity', 'jaccard_similarity_nouns', 'glove_similarity', 'kl_divergence', 'ngram_overlap', 'semantic_similarity'], ['jaccard_similarity', 'jaccard_similarity_nouns', 'glove_similarity', 'kl_divergence', 'ngram_overlap', 'LDA_Score'], ['jaccard_similarity', 'jaccard_similarity_nouns', 'glove_similarity', 'kl_divergence', 'semantic_similarity', 'LDA_Score'], ['jaccard_similarity', 'jaccard_similarity_nouns', 'glove_similarity', 'ngram_overlap', 'semantic_similarity', 'LDA_Score'], ['jaccard_similarity', 'jaccard_similarity_nouns', 'kl_divergence', 'ngram_overlap', 'semantic_similarity', 'LDA_Score'], ['jaccard_similarity', 'glove_similarity', 'kl_divergence', 'ngram_overlap', 'semantic_similarity', 'LDA_Score'], ['jaccard_similarity_nouns', 'glove_similarity', 'kl_divergence', 'ngram_overlap', 'semantic_similarity', 'LDA_Score'], ['jaccard_similarity', 'jaccard_similarity_nouns', 'glove_similarity', 'kl_divergence', 'ngram_overlap', 'semantic_similarity', 'LDA_Score']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "x0I1di3J2c55",
        "outputId": "2446fcc3-2d47-4d47-f51d-dc974dbba619"
      },
      "source": [
        "train['stance_base'] "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        unrelated\n",
              "1          related\n",
              "2        unrelated\n",
              "3        unrelated\n",
              "4          related\n",
              "           ...    \n",
              "75380      related\n",
              "75381      related\n",
              "75382      related\n",
              "75383      related\n",
              "75384      related\n",
              "Name: stance_base, Length: 75385, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "qainjzNg2c56",
        "outputId": "cf336fd4-9586-4764-86f7-d13edb0b4712"
      },
      "source": [
        "train[\"Stance\"].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['unrelated', 'agree', 'disagree', 'discuss'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DOs9SRr2c56",
        "outputId": "32fb4416-3cf4-4f7d-a901-81962f9d0c47"
      },
      "source": [
        "test[\"Stance\"].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['agree', 'discuss', 'disagree', 'unrelated'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhwDgoEY2c57"
      },
      "source": [
        "#train =  train[(train.Stance == 'disagree') | (train.Stance == 'discuss')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCtqEdL32c57",
        "outputId": "20fabe7e-a3fb-4dd3-8d77-01d24131bb42"
      },
      "source": [
        "train[\"Stance\"].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['unrelated', 'agree', 'disagree', 'discuss'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvixjcEj2c57",
        "outputId": "a12f18dd-0a38-4c9d-92f1-c2f92ca1897f"
      },
      "source": [
        "#test =  test[(test.Stance == 'disagree') | (test.Stance == 'discuss')]\n",
        "\n",
        "test[\"Stance\"].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['agree', 'discuss', 'disagree', 'unrelated'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xE0Nks_P2c58"
      },
      "source": [
        "def combinations_test_data(combi_list):    # creat a function to generate 49 combination feature from 7-features\n",
        "    score = []\n",
        "    for i in combi_list:\n",
        "        from sklearn.metrics import accuracy_score\n",
        "        from sklearn.model_selection import train_test_split\n",
        "        from sklearn.ensemble import RandomForestClassifier\n",
        "        from nltk.corpus import stopwords\n",
        "\n",
        "\n",
        "        #xtrain,xtest,ytrain,ytest = train_test_split(x,y,test_size=0.1, random_state = 101)\n",
        "        xtrain3 = train[i]\n",
        "        ytrain3 = train['stance_base'] \n",
        "        xtest3 = test[i]\n",
        "        ytest3 = test[\"stance_base\"]\n",
        "        rg = RandomForestClassifier(n_estimators=100,n_jobs=-1)\n",
        "\n",
        "\n",
        "        r = len(i)\n",
        "        #print('X Training shape',xtrain.shape)\n",
        "        #print('Y Training shape',ytrain.shape)\n",
        "        xtrain3 = xtrain3.values.reshape(-1,r)\n",
        "        xtest3 = xtest3.values.reshape(-1,r)\n",
        "\n",
        "        rg.fit(xtrain3,ytrain3)\n",
        "        ypred2 = rg.predict(xtest3)\n",
        "        print('Accuracy score on three class ',accuracy_score(ypred2,ytest3))\n",
        "        print(i)\n",
        "\n",
        "        #ypred2[:20]\n",
        "\n",
        "        from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "        print(classification_report(ypred2,ytest3))\n",
        "        print(confusion_matrix(ypred2,ytest3))\n",
        "        score.append(accuracy_score(ypred2,ytest3))\n",
        "    print(\"max accuracy\" ,max(score))\n",
        "    print(score)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "fY2KIXup2c58",
        "outputId": "46fde1e1-e757-4c90-e69f-1ce755aa8b23"
      },
      "source": [
        "combinations_test_data(combi_list = xyz)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score on three class  0.7735849056603774\n",
            "['jaccard_similarity']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.87      0.79      0.83       145\n",
            "   unrelated       0.62      0.75      0.68        67\n",
            "\n",
            "    accuracy                           0.77       212\n",
            "   macro avg       0.74      0.77      0.75       212\n",
            "weighted avg       0.79      0.77      0.78       212\n",
            "\n",
            "[[114  31]\n",
            " [ 17  50]]\n",
            "Accuracy score on three class  0.8018867924528302\n",
            "['jaccard_similarity_nouns']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.84      0.84      0.84       131\n",
            "   unrelated       0.74      0.74      0.74        81\n",
            "\n",
            "    accuracy                           0.80       212\n",
            "   macro avg       0.79      0.79      0.79       212\n",
            "weighted avg       0.80      0.80      0.80       212\n",
            "\n",
            "[[110  21]\n",
            " [ 21  60]]\n",
            "Accuracy score on three class  0.5707547169811321\n",
            "['glove_similarity']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.42      0.79      0.55        70\n",
            "   unrelated       0.81      0.46      0.59       142\n",
            "\n",
            "    accuracy                           0.57       212\n",
            "   macro avg       0.62      0.63      0.57       212\n",
            "weighted avg       0.68      0.57      0.58       212\n",
            "\n",
            "[[55 15]\n",
            " [76 66]]\n",
            "Accuracy score on three class  0.6981132075471698\n",
            "['kl_divergence']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.85      0.72      0.78       155\n",
            "   unrelated       0.46      0.65      0.54        57\n",
            "\n",
            "    accuracy                           0.70       212\n",
            "   macro avg       0.65      0.68      0.66       212\n",
            "weighted avg       0.74      0.70      0.71       212\n",
            "\n",
            "[[111  44]\n",
            " [ 20  37]]\n",
            "Accuracy score on three class  0.38207547169811323\n",
            "['ngram_overlap']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.00      0.00      0.00         0\n",
            "   unrelated       1.00      0.38      0.55       212\n",
            "\n",
            "    accuracy                           0.38       212\n",
            "   macro avg       0.50      0.19      0.28       212\n",
            "weighted avg       1.00      0.38      0.55       212\n",
            "\n",
            "[[  0   0]\n",
            " [131  81]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy score on three class  0.3867924528301887\n",
            "['semantic_similarity']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.13      0.52      0.21        33\n",
            "   unrelated       0.80      0.36      0.50       179\n",
            "\n",
            "    accuracy                           0.39       212\n",
            "   macro avg       0.47      0.44      0.35       212\n",
            "weighted avg       0.70      0.39      0.45       212\n",
            "\n",
            "[[ 17  16]\n",
            " [114  65]]\n",
            "Accuracy score on three class  0.37264150943396224\n",
            "['LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.01      0.25      0.01         4\n",
            "   unrelated       0.96      0.38      0.54       208\n",
            "\n",
            "    accuracy                           0.37       212\n",
            "   macro avg       0.49      0.31      0.28       212\n",
            "weighted avg       0.94      0.37      0.53       212\n",
            "\n",
            "[[  1   3]\n",
            " [130  78]]\n",
            "Accuracy score on three class  0.7311320754716981\n",
            "['jaccard_similarity', 'jaccard_similarity_nouns']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.85      0.75      0.80       150\n",
            "   unrelated       0.53      0.69      0.60        62\n",
            "\n",
            "    accuracy                           0.73       212\n",
            "   macro avg       0.69      0.72      0.70       212\n",
            "weighted avg       0.76      0.73      0.74       212\n",
            "\n",
            "[[112  38]\n",
            " [ 19  43]]\n",
            "Accuracy score on three class  0.7264150943396226\n",
            "['jaccard_similarity', 'glove_similarity']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.83      0.75      0.79       145\n",
            "   unrelated       0.56      0.67      0.61        67\n",
            "\n",
            "    accuracy                           0.73       212\n",
            "   macro avg       0.69      0.71      0.70       212\n",
            "weighted avg       0.74      0.73      0.73       212\n",
            "\n",
            "[[109  36]\n",
            " [ 22  45]]\n",
            "Accuracy score on three class  0.75\n",
            "['jaccard_similarity', 'kl_divergence']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.92      0.74      0.82       162\n",
            "   unrelated       0.48      0.78      0.60        50\n",
            "\n",
            "    accuracy                           0.75       212\n",
            "   macro avg       0.70      0.76      0.71       212\n",
            "weighted avg       0.81      0.75      0.77       212\n",
            "\n",
            "[[120  42]\n",
            " [ 11  39]]\n",
            "Accuracy score on three class  0.7594339622641509\n",
            "['jaccard_similarity', 'ngram_overlap']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.90      0.76      0.82       156\n",
            "   unrelated       0.53      0.77      0.63        56\n",
            "\n",
            "    accuracy                           0.76       212\n",
            "   macro avg       0.72      0.76      0.73       212\n",
            "weighted avg       0.80      0.76      0.77       212\n",
            "\n",
            "[[118  38]\n",
            " [ 13  43]]\n",
            "Accuracy score on three class  0.6132075471698113\n",
            "['jaccard_similarity', 'semantic_similarity']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.53      0.77      0.63        91\n",
            "   unrelated       0.74      0.50      0.59       121\n",
            "\n",
            "    accuracy                           0.61       212\n",
            "   macro avg       0.64      0.63      0.61       212\n",
            "weighted avg       0.65      0.61      0.61       212\n",
            "\n",
            "[[70 21]\n",
            " [61 60]]\n",
            "Accuracy score on three class  0.7688679245283019\n",
            "['jaccard_similarity', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.85      0.79      0.82       142\n",
            "   unrelated       0.63      0.73      0.68        70\n",
            "\n",
            "    accuracy                           0.77       212\n",
            "   macro avg       0.74      0.76      0.75       212\n",
            "weighted avg       0.78      0.77      0.77       212\n",
            "\n",
            "[[112  30]\n",
            " [ 19  51]]\n",
            "Accuracy score on three class  0.7924528301886793\n",
            "['jaccard_similarity_nouns', 'glove_similarity']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.85      0.82      0.84       137\n",
            "   unrelated       0.69      0.75      0.72        75\n",
            "\n",
            "    accuracy                           0.79       212\n",
            "   macro avg       0.77      0.78      0.78       212\n",
            "weighted avg       0.80      0.79      0.79       212\n",
            "\n",
            "[[112  25]\n",
            " [ 19  56]]\n",
            "Accuracy score on three class  0.7641509433962265\n",
            "['jaccard_similarity_nouns', 'kl_divergence']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.89      0.76      0.82       153\n",
            "   unrelated       0.56      0.76      0.64        59\n",
            "\n",
            "    accuracy                           0.76       212\n",
            "   macro avg       0.72      0.76      0.73       212\n",
            "weighted avg       0.80      0.76      0.77       212\n",
            "\n",
            "[[117  36]\n",
            " [ 14  45]]\n",
            "Accuracy score on three class  0.7924528301886793\n",
            "['jaccard_similarity_nouns', 'ngram_overlap']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.88      0.80      0.84       143\n",
            "   unrelated       0.65      0.77      0.71        69\n",
            "\n",
            "    accuracy                           0.79       212\n",
            "   macro avg       0.77      0.79      0.77       212\n",
            "weighted avg       0.81      0.79      0.80       212\n",
            "\n",
            "[[115  28]\n",
            " [ 16  53]]\n",
            "Accuracy score on three class  0.5943396226415094\n",
            "['jaccard_similarity_nouns', 'semantic_similarity']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.48      0.78      0.59        81\n",
            "   unrelated       0.78      0.48      0.59       131\n",
            "\n",
            "    accuracy                           0.59       212\n",
            "   macro avg       0.63      0.63      0.59       212\n",
            "weighted avg       0.66      0.59      0.59       212\n",
            "\n",
            "[[63 18]\n",
            " [68 63]]\n",
            "Accuracy score on three class  0.7877358490566038\n",
            "['jaccard_similarity_nouns', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.83      0.83      0.83       132\n",
            "   unrelated       0.72      0.72      0.72        80\n",
            "\n",
            "    accuracy                           0.79       212\n",
            "   macro avg       0.77      0.78      0.77       212\n",
            "weighted avg       0.79      0.79      0.79       212\n",
            "\n",
            "[[109  23]\n",
            " [ 22  58]]\n",
            "Accuracy score on three class  0.5943396226415094\n",
            "['glove_similarity', 'kl_divergence']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.60      0.70      0.65       113\n",
            "   unrelated       0.58      0.47      0.52        99\n",
            "\n",
            "    accuracy                           0.59       212\n",
            "   macro avg       0.59      0.59      0.58       212\n",
            "weighted avg       0.59      0.59      0.59       212\n",
            "\n",
            "[[79 34]\n",
            " [52 47]]\n",
            "Accuracy score on three class  0.5660377358490566\n",
            "['glove_similarity', 'ngram_overlap']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.50      0.71      0.59        91\n",
            "   unrelated       0.68      0.45      0.54       121\n",
            "\n",
            "    accuracy                           0.57       212\n",
            "   macro avg       0.59      0.58      0.57       212\n",
            "weighted avg       0.60      0.57      0.56       212\n",
            "\n",
            "[[65 26]\n",
            " [66 55]]\n",
            "Accuracy score on three class  0.42924528301886794\n",
            "['glove_similarity', 'semantic_similarity']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.18      0.64      0.28        36\n",
            "   unrelated       0.84      0.39      0.53       176\n",
            "\n",
            "    accuracy                           0.43       212\n",
            "   macro avg       0.51      0.51      0.40       212\n",
            "weighted avg       0.73      0.43      0.49       212\n",
            "\n",
            "[[ 23  13]\n",
            " [108  68]]\n",
            "Accuracy score on three class  0.5188679245283019\n",
            "['glove_similarity', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.35      0.73      0.47        63\n",
            "   unrelated       0.79      0.43      0.56       149\n",
            "\n",
            "    accuracy                           0.52       212\n",
            "   macro avg       0.57      0.58      0.52       212\n",
            "weighted avg       0.66      0.52      0.53       212\n",
            "\n",
            "[[46 17]\n",
            " [85 64]]\n",
            "Accuracy score on three class  0.6650943396226415\n",
            "['kl_divergence', 'ngram_overlap']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.83      0.69      0.75       158\n",
            "   unrelated       0.40      0.59      0.47        54\n",
            "\n",
            "    accuracy                           0.67       212\n",
            "   macro avg       0.61      0.64      0.61       212\n",
            "weighted avg       0.72      0.67      0.68       212\n",
            "\n",
            "[[109  49]\n",
            " [ 22  32]]\n",
            "Accuracy score on three class  0.4669811320754717\n",
            "['kl_divergence', 'semantic_similarity']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.32      0.64      0.43        66\n",
            "   unrelated       0.70      0.39      0.50       146\n",
            "\n",
            "    accuracy                           0.47       212\n",
            "   macro avg       0.51      0.51      0.46       212\n",
            "weighted avg       0.58      0.47      0.48       212\n",
            "\n",
            "[[42 24]\n",
            " [89 57]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy score on three class  0.6698113207547169\n",
            "['kl_divergence', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.79      0.71      0.75       145\n",
            "   unrelated       0.48      0.58      0.53        67\n",
            "\n",
            "    accuracy                           0.67       212\n",
            "   macro avg       0.63      0.65      0.64       212\n",
            "weighted avg       0.69      0.67      0.68       212\n",
            "\n",
            "[[103  42]\n",
            " [ 28  39]]\n",
            "Accuracy score on three class  0.38207547169811323\n",
            "['ngram_overlap', 'semantic_similarity']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.21      0.50      0.29        54\n",
            "   unrelated       0.67      0.34      0.45       158\n",
            "\n",
            "    accuracy                           0.38       212\n",
            "   macro avg       0.44      0.42      0.37       212\n",
            "weighted avg       0.55      0.38      0.41       212\n",
            "\n",
            "[[ 27  27]\n",
            " [104  54]]\n",
            "Accuracy score on three class  0.37264150943396224\n",
            "['ngram_overlap', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.02      0.33      0.03         6\n",
            "   unrelated       0.95      0.37      0.54       206\n",
            "\n",
            "    accuracy                           0.37       212\n",
            "   macro avg       0.48      0.35      0.28       212\n",
            "weighted avg       0.92      0.37      0.52       212\n",
            "\n",
            "[[  2   4]\n",
            " [129  77]]\n",
            "Accuracy score on three class  0.3915094339622642\n",
            "['semantic_similarity', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.15      0.53      0.24        38\n",
            "   unrelated       0.78      0.36      0.49       174\n",
            "\n",
            "    accuracy                           0.39       212\n",
            "   macro avg       0.47      0.44      0.37       212\n",
            "weighted avg       0.67      0.39      0.45       212\n",
            "\n",
            "[[ 20  18]\n",
            " [111  63]]\n",
            "Accuracy score on three class  0.75\n",
            "['jaccard_similarity', 'jaccard_similarity_nouns', 'glove_similarity']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.86      0.76      0.81       148\n",
            "   unrelated       0.57      0.72      0.63        64\n",
            "\n",
            "    accuracy                           0.75       212\n",
            "   macro avg       0.72      0.74      0.72       212\n",
            "weighted avg       0.77      0.75      0.76       212\n",
            "\n",
            "[[113  35]\n",
            " [ 18  46]]\n",
            "Accuracy score on three class  0.7452830188679245\n",
            "['jaccard_similarity', 'jaccard_similarity_nouns', 'kl_divergence']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.92      0.74      0.82       163\n",
            "   unrelated       0.47      0.78      0.58        49\n",
            "\n",
            "    accuracy                           0.75       212\n",
            "   macro avg       0.69      0.76      0.70       212\n",
            "weighted avg       0.81      0.75      0.76       212\n",
            "\n",
            "[[120  43]\n",
            " [ 11  38]]\n",
            "Accuracy score on three class  0.7547169811320755\n",
            "['jaccard_similarity', 'jaccard_similarity_nouns', 'ngram_overlap']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.92      0.74      0.82       163\n",
            "   unrelated       0.48      0.80      0.60        49\n",
            "\n",
            "    accuracy                           0.75       212\n",
            "   macro avg       0.70      0.77      0.71       212\n",
            "weighted avg       0.82      0.75      0.77       212\n",
            "\n",
            "[[121  42]\n",
            " [ 10  39]]\n",
            "Accuracy score on three class  0.6839622641509434\n",
            "['jaccard_similarity', 'jaccard_similarity_nouns', 'semantic_similarity']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.63      0.82      0.71       100\n",
            "   unrelated       0.78      0.56      0.65       112\n",
            "\n",
            "    accuracy                           0.68       212\n",
            "   macro avg       0.70      0.69      0.68       212\n",
            "weighted avg       0.71      0.68      0.68       212\n",
            "\n",
            "[[82 18]\n",
            " [49 63]]\n",
            "Accuracy score on three class  0.7641509433962265\n",
            "['jaccard_similarity', 'jaccard_similarity_nouns', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.86      0.78      0.82       145\n",
            "   unrelated       0.60      0.73      0.66        67\n",
            "\n",
            "    accuracy                           0.76       212\n",
            "   macro avg       0.73      0.76      0.74       212\n",
            "weighted avg       0.78      0.76      0.77       212\n",
            "\n",
            "[[113  32]\n",
            " [ 18  49]]\n",
            "Accuracy score on three class  0.7452830188679245\n",
            "['jaccard_similarity', 'glove_similarity', 'kl_divergence']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.92      0.73      0.82       165\n",
            "   unrelated       0.46      0.79      0.58        47\n",
            "\n",
            "    accuracy                           0.75       212\n",
            "   macro avg       0.69      0.76      0.70       212\n",
            "weighted avg       0.82      0.75      0.76       212\n",
            "\n",
            "[[121  44]\n",
            " [ 10  37]]\n",
            "Accuracy score on three class  0.7264150943396226\n",
            "['jaccard_similarity', 'glove_similarity', 'ngram_overlap']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.86      0.74      0.80       153\n",
            "   unrelated       0.51      0.69      0.59        59\n",
            "\n",
            "    accuracy                           0.73       212\n",
            "   macro avg       0.68      0.72      0.69       212\n",
            "weighted avg       0.76      0.73      0.74       212\n",
            "\n",
            "[[113  40]\n",
            " [ 18  41]]\n",
            "Accuracy score on three class  0.6273584905660378\n",
            "['jaccard_similarity', 'glove_similarity', 'semantic_similarity']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.56      0.78      0.65        94\n",
            "   unrelated       0.74      0.51      0.60       118\n",
            "\n",
            "    accuracy                           0.63       212\n",
            "   macro avg       0.65      0.64      0.63       212\n",
            "weighted avg       0.66      0.63      0.62       212\n",
            "\n",
            "[[73 21]\n",
            " [58 60]]\n",
            "Accuracy score on three class  0.7122641509433962\n",
            "['jaccard_similarity', 'glove_similarity', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.76      0.77      0.77       130\n",
            "   unrelated       0.63      0.62      0.63        82\n",
            "\n",
            "    accuracy                           0.71       212\n",
            "   macro avg       0.70      0.70      0.70       212\n",
            "weighted avg       0.71      0.71      0.71       212\n",
            "\n",
            "[[100  30]\n",
            " [ 31  51]]\n",
            "Accuracy score on three class  0.7075471698113207\n",
            "['jaccard_similarity', 'kl_divergence', 'ngram_overlap']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.91      0.70      0.79       169\n",
            "   unrelated       0.38      0.72      0.50        43\n",
            "\n",
            "    accuracy                           0.71       212\n",
            "   macro avg       0.65      0.71      0.65       212\n",
            "weighted avg       0.80      0.71      0.73       212\n",
            "\n",
            "[[119  50]\n",
            " [ 12  31]]\n",
            "Accuracy score on three class  0.7311320754716981\n",
            "['jaccard_similarity', 'kl_divergence', 'semantic_similarity']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.87      0.74      0.80       154\n",
            "   unrelated       0.51      0.71      0.59        58\n",
            "\n",
            "    accuracy                           0.73       212\n",
            "   macro avg       0.69      0.72      0.69       212\n",
            "weighted avg       0.77      0.73      0.74       212\n",
            "\n",
            "[[114  40]\n",
            " [ 17  41]]\n",
            "Accuracy score on three class  0.7405660377358491\n",
            "['jaccard_similarity', 'kl_divergence', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.91      0.73      0.81       162\n",
            "   unrelated       0.47      0.76      0.58        50\n",
            "\n",
            "    accuracy                           0.74       212\n",
            "   macro avg       0.69      0.75      0.70       212\n",
            "weighted avg       0.80      0.74      0.76       212\n",
            "\n",
            "[[119  43]\n",
            " [ 12  38]]\n",
            "Accuracy score on three class  0.589622641509434\n",
            "['jaccard_similarity', 'ngram_overlap', 'semantic_similarity']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.56      0.72      0.63       102\n",
            "   unrelated       0.64      0.47      0.54       110\n",
            "\n",
            "    accuracy                           0.59       212\n",
            "   macro avg       0.60      0.59      0.59       212\n",
            "weighted avg       0.60      0.59      0.58       212\n",
            "\n",
            "[[73 29]\n",
            " [58 52]]\n",
            "Accuracy score on three class  0.7594339622641509\n",
            "['jaccard_similarity', 'ngram_overlap', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.89      0.76      0.82       154\n",
            "   unrelated       0.54      0.76      0.63        58\n",
            "\n",
            "    accuracy                           0.76       212\n",
            "   macro avg       0.72      0.76      0.73       212\n",
            "weighted avg       0.80      0.76      0.77       212\n",
            "\n",
            "[[117  37]\n",
            " [ 14  44]]\n",
            "Accuracy score on three class  0.5754716981132075\n",
            "['jaccard_similarity', 'semantic_similarity', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.47      0.75      0.58        81\n",
            "   unrelated       0.75      0.47      0.58       131\n",
            "\n",
            "    accuracy                           0.58       212\n",
            "   macro avg       0.61      0.61      0.58       212\n",
            "weighted avg       0.64      0.58      0.58       212\n",
            "\n",
            "[[61 20]\n",
            " [70 61]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy score on three class  0.7735849056603774\n",
            "['jaccard_similarity_nouns', 'glove_similarity', 'kl_divergence']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.91      0.77      0.83       155\n",
            "   unrelated       0.56      0.79      0.65        57\n",
            "\n",
            "    accuracy                           0.77       212\n",
            "   macro avg       0.73      0.78      0.74       212\n",
            "weighted avg       0.81      0.77      0.78       212\n",
            "\n",
            "[[119  36]\n",
            " [ 12  45]]\n",
            "Accuracy score on three class  0.8066037735849056\n",
            "['jaccard_similarity_nouns', 'glove_similarity', 'ngram_overlap']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.88      0.82      0.85       140\n",
            "   unrelated       0.69      0.78      0.73        72\n",
            "\n",
            "    accuracy                           0.81       212\n",
            "   macro avg       0.78      0.80      0.79       212\n",
            "weighted avg       0.81      0.81      0.81       212\n",
            "\n",
            "[[115  25]\n",
            " [ 16  56]]\n",
            "Accuracy score on three class  0.6084905660377359\n",
            "['jaccard_similarity_nouns', 'glove_similarity', 'semantic_similarity']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.49      0.80      0.61        80\n",
            "   unrelated       0.80      0.49      0.61       132\n",
            "\n",
            "    accuracy                           0.61       212\n",
            "   macro avg       0.65      0.65      0.61       212\n",
            "weighted avg       0.68      0.61      0.61       212\n",
            "\n",
            "[[64 16]\n",
            " [67 65]]\n",
            "Accuracy score on three class  0.7877358490566038\n",
            "['jaccard_similarity_nouns', 'glove_similarity', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.84      0.82      0.83       134\n",
            "   unrelated       0.70      0.73      0.72        78\n",
            "\n",
            "    accuracy                           0.79       212\n",
            "   macro avg       0.77      0.78      0.77       212\n",
            "weighted avg       0.79      0.79      0.79       212\n",
            "\n",
            "[[110  24]\n",
            " [ 21  57]]\n",
            "Accuracy score on three class  0.7452830188679245\n",
            "['jaccard_similarity_nouns', 'kl_divergence', 'ngram_overlap']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.90      0.74      0.81       159\n",
            "   unrelated       0.49      0.75      0.60        53\n",
            "\n",
            "    accuracy                           0.75       212\n",
            "   macro avg       0.70      0.75      0.71       212\n",
            "weighted avg       0.80      0.75      0.76       212\n",
            "\n",
            "[[118  41]\n",
            " [ 13  40]]\n",
            "Accuracy score on three class  0.7358490566037735\n",
            "['jaccard_similarity_nouns', 'kl_divergence', 'semantic_similarity']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.82      0.77      0.79       139\n",
            "   unrelated       0.60      0.67      0.64        73\n",
            "\n",
            "    accuracy                           0.74       212\n",
            "   macro avg       0.71      0.72      0.71       212\n",
            "weighted avg       0.74      0.74      0.74       212\n",
            "\n",
            "[[107  32]\n",
            " [ 24  49]]\n",
            "Accuracy score on three class  0.7688679245283019\n",
            "['jaccard_similarity_nouns', 'kl_divergence', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.89      0.77      0.83       152\n",
            "   unrelated       0.57      0.77      0.65        60\n",
            "\n",
            "    accuracy                           0.77       212\n",
            "   macro avg       0.73      0.77      0.74       212\n",
            "weighted avg       0.80      0.77      0.78       212\n",
            "\n",
            "[[117  35]\n",
            " [ 14  46]]\n",
            "Accuracy score on three class  0.6037735849056604\n",
            "['jaccard_similarity_nouns', 'ngram_overlap', 'semantic_similarity']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.55      0.74      0.63        97\n",
            "   unrelated       0.69      0.49      0.57       115\n",
            "\n",
            "    accuracy                           0.60       212\n",
            "   macro avg       0.62      0.61      0.60       212\n",
            "weighted avg       0.63      0.60      0.60       212\n",
            "\n",
            "[[72 25]\n",
            " [59 56]]\n",
            "Accuracy score on three class  0.75\n",
            "['jaccard_similarity_nouns', 'ngram_overlap', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.82      0.78      0.80       138\n",
            "   unrelated       0.63      0.69      0.66        74\n",
            "\n",
            "    accuracy                           0.75       212\n",
            "   macro avg       0.73      0.74      0.73       212\n",
            "weighted avg       0.76      0.75      0.75       212\n",
            "\n",
            "[[108  30]\n",
            " [ 23  51]]\n",
            "Accuracy score on three class  0.5566037735849056\n",
            "['jaccard_similarity_nouns', 'semantic_similarity', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.41      0.76      0.53        71\n",
            "   unrelated       0.79      0.45      0.58       141\n",
            "\n",
            "    accuracy                           0.56       212\n",
            "   macro avg       0.60      0.61      0.56       212\n",
            "weighted avg       0.66      0.56      0.56       212\n",
            "\n",
            "[[54 17]\n",
            " [77 64]]\n",
            "Accuracy score on three class  0.5707547169811321\n",
            "['glove_similarity', 'kl_divergence', 'ngram_overlap']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.60      0.67      0.63       118\n",
            "   unrelated       0.52      0.45      0.48        94\n",
            "\n",
            "    accuracy                           0.57       212\n",
            "   macro avg       0.56      0.56      0.56       212\n",
            "weighted avg       0.57      0.57      0.57       212\n",
            "\n",
            "[[79 39]\n",
            " [52 42]]\n",
            "Accuracy score on three class  0.5\n",
            "['glove_similarity', 'kl_divergence', 'semantic_similarity']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.37      0.68      0.48        71\n",
            "   unrelated       0.72      0.41      0.52       141\n",
            "\n",
            "    accuracy                           0.50       212\n",
            "   macro avg       0.54      0.54      0.50       212\n",
            "weighted avg       0.60      0.50      0.51       212\n",
            "\n",
            "[[48 23]\n",
            " [83 58]]\n",
            "Accuracy score on three class  0.5943396226415094\n",
            "['glove_similarity', 'kl_divergence', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.62      0.69      0.65       117\n",
            "   unrelated       0.56      0.47      0.51        95\n",
            "\n",
            "    accuracy                           0.59       212\n",
            "   macro avg       0.59      0.58      0.58       212\n",
            "weighted avg       0.59      0.59      0.59       212\n",
            "\n",
            "[[81 36]\n",
            " [50 45]]\n",
            "Accuracy score on three class  0.4481132075471698\n",
            "['glove_similarity', 'ngram_overlap', 'semantic_similarity']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.27      0.62      0.37        56\n",
            "   unrelated       0.74      0.38      0.51       156\n",
            "\n",
            "    accuracy                           0.45       212\n",
            "   macro avg       0.50      0.50      0.44       212\n",
            "weighted avg       0.62      0.45      0.47       212\n",
            "\n",
            "[[35 21]\n",
            " [96 60]]\n",
            "Accuracy score on three class  0.5283018867924528\n",
            "['glove_similarity', 'ngram_overlap', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.41      0.70      0.52        77\n",
            "   unrelated       0.72      0.43      0.54       135\n",
            "\n",
            "    accuracy                           0.53       212\n",
            "   macro avg       0.56      0.57      0.53       212\n",
            "weighted avg       0.61      0.53      0.53       212\n",
            "\n",
            "[[54 23]\n",
            " [77 58]]\n",
            "Accuracy score on three class  0.39622641509433965\n",
            "['glove_similarity', 'semantic_similarity', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.15      0.54      0.23        35\n",
            "   unrelated       0.80      0.37      0.50       177\n",
            "\n",
            "    accuracy                           0.40       212\n",
            "   macro avg       0.47      0.46      0.37       212\n",
            "weighted avg       0.69      0.40      0.46       212\n",
            "\n",
            "[[ 19  16]\n",
            " [112  65]]\n",
            "Accuracy score on three class  0.39622641509433965\n",
            "['kl_divergence', 'ngram_overlap', 'semantic_similarity']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.30      0.52      0.38        75\n",
            "   unrelated       0.56      0.33      0.41       137\n",
            "\n",
            "    accuracy                           0.40       212\n",
            "   macro avg       0.43      0.42      0.40       212\n",
            "weighted avg       0.46      0.40      0.40       212\n",
            "\n",
            "[[39 36]\n",
            " [92 45]]\n",
            "Accuracy score on three class  0.6367924528301887\n",
            "['kl_divergence', 'ngram_overlap', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.75      0.69      0.72       142\n",
            "   unrelated       0.46      0.53      0.49        70\n",
            "\n",
            "    accuracy                           0.64       212\n",
            "   macro avg       0.60      0.61      0.60       212\n",
            "weighted avg       0.65      0.64      0.64       212\n",
            "\n",
            "[[98 44]\n",
            " [33 37]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy score on three class  0.4339622641509434\n",
            "['kl_divergence', 'semantic_similarity', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.30      0.58      0.39        67\n",
            "   unrelated       0.65      0.37      0.47       145\n",
            "\n",
            "    accuracy                           0.43       212\n",
            "   macro avg       0.48      0.47      0.43       212\n",
            "weighted avg       0.54      0.43      0.45       212\n",
            "\n",
            "[[39 28]\n",
            " [92 53]]\n",
            "Accuracy score on three class  0.38207547169811323\n",
            "['ngram_overlap', 'semantic_similarity', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.20      0.50      0.28        52\n",
            "   unrelated       0.68      0.34      0.46       160\n",
            "\n",
            "    accuracy                           0.38       212\n",
            "   macro avg       0.44      0.42      0.37       212\n",
            "weighted avg       0.56      0.38      0.41       212\n",
            "\n",
            "[[ 26  26]\n",
            " [105  55]]\n",
            "Accuracy score on three class  0.75\n",
            "['jaccard_similarity', 'jaccard_similarity_nouns', 'glove_similarity', 'kl_divergence']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.92      0.74      0.82       164\n",
            "   unrelated       0.47      0.79      0.59        48\n",
            "\n",
            "    accuracy                           0.75       212\n",
            "   macro avg       0.70      0.76      0.70       212\n",
            "weighted avg       0.82      0.75      0.77       212\n",
            "\n",
            "[[121  43]\n",
            " [ 10  38]]\n",
            "Accuracy score on three class  0.7547169811320755\n",
            "['jaccard_similarity', 'jaccard_similarity_nouns', 'glove_similarity', 'ngram_overlap']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.92      0.74      0.82       163\n",
            "   unrelated       0.48      0.80      0.60        49\n",
            "\n",
            "    accuracy                           0.75       212\n",
            "   macro avg       0.70      0.77      0.71       212\n",
            "weighted avg       0.82      0.75      0.77       212\n",
            "\n",
            "[[121  42]\n",
            " [ 10  39]]\n",
            "Accuracy score on three class  0.660377358490566\n",
            "['jaccard_similarity', 'jaccard_similarity_nouns', 'glove_similarity', 'semantic_similarity']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.62      0.79      0.69       103\n",
            "   unrelated       0.73      0.54      0.62       109\n",
            "\n",
            "    accuracy                           0.66       212\n",
            "   macro avg       0.67      0.66      0.66       212\n",
            "weighted avg       0.67      0.66      0.66       212\n",
            "\n",
            "[[81 22]\n",
            " [50 59]]\n",
            "Accuracy score on three class  0.75\n",
            "['jaccard_similarity', 'jaccard_similarity_nouns', 'glove_similarity', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.85      0.77      0.81       144\n",
            "   unrelated       0.59      0.71      0.64        68\n",
            "\n",
            "    accuracy                           0.75       212\n",
            "   macro avg       0.72      0.74      0.73       212\n",
            "weighted avg       0.77      0.75      0.75       212\n",
            "\n",
            "[[111  33]\n",
            " [ 20  48]]\n",
            "Accuracy score on three class  0.7169811320754716\n",
            "['jaccard_similarity', 'jaccard_similarity_nouns', 'kl_divergence', 'ngram_overlap']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.92      0.71      0.80       171\n",
            "   unrelated       0.38      0.76      0.51        41\n",
            "\n",
            "    accuracy                           0.72       212\n",
            "   macro avg       0.65      0.73      0.65       212\n",
            "weighted avg       0.82      0.72      0.74       212\n",
            "\n",
            "[[121  50]\n",
            " [ 10  31]]\n",
            "Accuracy score on three class  0.75\n",
            "['jaccard_similarity', 'jaccard_similarity_nouns', 'kl_divergence', 'semantic_similarity']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.88      0.76      0.81       152\n",
            "   unrelated       0.54      0.73      0.62        60\n",
            "\n",
            "    accuracy                           0.75       212\n",
            "   macro avg       0.71      0.74      0.72       212\n",
            "weighted avg       0.78      0.75      0.76       212\n",
            "\n",
            "[[115  37]\n",
            " [ 16  44]]\n",
            "Accuracy score on three class  0.75\n",
            "['jaccard_similarity', 'jaccard_similarity_nouns', 'kl_divergence', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.92      0.74      0.82       162\n",
            "   unrelated       0.48      0.78      0.60        50\n",
            "\n",
            "    accuracy                           0.75       212\n",
            "   macro avg       0.70      0.76      0.71       212\n",
            "weighted avg       0.81      0.75      0.77       212\n",
            "\n",
            "[[120  42]\n",
            " [ 11  39]]\n",
            "Accuracy score on three class  0.6462264150943396\n",
            "['jaccard_similarity', 'jaccard_similarity_nouns', 'ngram_overlap', 'semantic_similarity']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.66      0.74      0.70       118\n",
            "   unrelated       0.62      0.53      0.57        94\n",
            "\n",
            "    accuracy                           0.65       212\n",
            "   macro avg       0.64      0.63      0.64       212\n",
            "weighted avg       0.64      0.65      0.64       212\n",
            "\n",
            "[[87 31]\n",
            " [44 50]]\n",
            "Accuracy score on three class  0.7735849056603774\n",
            "['jaccard_similarity', 'jaccard_similarity_nouns', 'ngram_overlap', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.92      0.76      0.83       159\n",
            "   unrelated       0.53      0.81      0.64        53\n",
            "\n",
            "    accuracy                           0.77       212\n",
            "   macro avg       0.73      0.79      0.74       212\n",
            "weighted avg       0.83      0.77      0.79       212\n",
            "\n",
            "[[121  38]\n",
            " [ 10  43]]\n",
            "Accuracy score on three class  0.660377358490566\n",
            "['jaccard_similarity', 'jaccard_similarity_nouns', 'semantic_similarity', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.59      0.81      0.68        95\n",
            "   unrelated       0.78      0.54      0.64       117\n",
            "\n",
            "    accuracy                           0.66       212\n",
            "   macro avg       0.68      0.67      0.66       212\n",
            "weighted avg       0.69      0.66      0.66       212\n",
            "\n",
            "[[77 18]\n",
            " [54 63]]\n",
            "Accuracy score on three class  0.7075471698113207\n",
            "['jaccard_similarity', 'glove_similarity', 'kl_divergence', 'ngram_overlap']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.92      0.70      0.79       171\n",
            "   unrelated       0.37      0.73      0.49        41\n",
            "\n",
            "    accuracy                           0.71       212\n",
            "   macro avg       0.64      0.72      0.64       212\n",
            "weighted avg       0.81      0.71      0.74       212\n",
            "\n",
            "[[120  51]\n",
            " [ 11  30]]\n",
            "Accuracy score on three class  0.7311320754716981\n",
            "['jaccard_similarity', 'glove_similarity', 'kl_divergence', 'semantic_similarity']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.85      0.75      0.80       148\n",
            "   unrelated       0.54      0.69      0.61        64\n",
            "\n",
            "    accuracy                           0.73       212\n",
            "   macro avg       0.70      0.72      0.70       212\n",
            "weighted avg       0.76      0.73      0.74       212\n",
            "\n",
            "[[111  37]\n",
            " [ 20  44]]\n",
            "Accuracy score on three class  0.7358490566037735\n",
            "['jaccard_similarity', 'glove_similarity', 'kl_divergence', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.91      0.73      0.81       163\n",
            "   unrelated       0.46      0.76      0.57        49\n",
            "\n",
            "    accuracy                           0.74       212\n",
            "   macro avg       0.68      0.74      0.69       212\n",
            "weighted avg       0.80      0.74      0.75       212\n",
            "\n",
            "[[119  44]\n",
            " [ 12  37]]\n",
            "Accuracy score on three class  0.6273584905660378\n",
            "['jaccard_similarity', 'glove_similarity', 'ngram_overlap', 'semantic_similarity']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.63      0.73      0.68       114\n",
            "   unrelated       0.62      0.51      0.56        98\n",
            "\n",
            "    accuracy                           0.63       212\n",
            "   macro avg       0.63      0.62      0.62       212\n",
            "weighted avg       0.63      0.63      0.62       212\n",
            "\n",
            "[[83 31]\n",
            " [48 50]]\n",
            "Accuracy score on three class  0.7547169811320755\n",
            "['jaccard_similarity', 'glove_similarity', 'ngram_overlap', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.85      0.78      0.81       143\n",
            "   unrelated       0.60      0.71      0.65        69\n",
            "\n",
            "    accuracy                           0.75       212\n",
            "   macro avg       0.73      0.74      0.73       212\n",
            "weighted avg       0.77      0.75      0.76       212\n",
            "\n",
            "[[111  32]\n",
            " [ 20  49]]\n",
            "Accuracy score on three class  0.6132075471698113\n",
            "['jaccard_similarity', 'glove_similarity', 'semantic_similarity', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.53      0.78      0.63        89\n",
            "   unrelated       0.75      0.50      0.60       123\n",
            "\n",
            "    accuracy                           0.61       212\n",
            "   macro avg       0.64      0.64      0.61       212\n",
            "weighted avg       0.66      0.61      0.61       212\n",
            "\n",
            "[[69 20]\n",
            " [62 61]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy score on three class  0.6792452830188679\n",
            "['jaccard_similarity', 'kl_divergence', 'ngram_overlap', 'semantic_similarity']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.84      0.70      0.76       157\n",
            "   unrelated       0.42      0.62      0.50        55\n",
            "\n",
            "    accuracy                           0.68       212\n",
            "   macro avg       0.63      0.66      0.63       212\n",
            "weighted avg       0.73      0.68      0.70       212\n",
            "\n",
            "[[110  47]\n",
            " [ 21  34]]\n",
            "Accuracy score on three class  0.7264150943396226\n",
            "['jaccard_similarity', 'kl_divergence', 'ngram_overlap', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.91      0.72      0.80       165\n",
            "   unrelated       0.43      0.74      0.55        47\n",
            "\n",
            "    accuracy                           0.73       212\n",
            "   macro avg       0.67      0.73      0.68       212\n",
            "weighted avg       0.80      0.73      0.75       212\n",
            "\n",
            "[[119  46]\n",
            " [ 12  35]]\n",
            "Accuracy score on three class  0.7216981132075472\n",
            "['jaccard_similarity', 'kl_divergence', 'semantic_similarity', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.83      0.75      0.79       146\n",
            "   unrelated       0.54      0.67      0.60        66\n",
            "\n",
            "    accuracy                           0.72       212\n",
            "   macro avg       0.69      0.71      0.69       212\n",
            "weighted avg       0.74      0.72      0.73       212\n",
            "\n",
            "[[109  37]\n",
            " [ 22  44]]\n",
            "Accuracy score on three class  0.6179245283018868\n",
            "['jaccard_similarity', 'ngram_overlap', 'semantic_similarity', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.59      0.74      0.66       104\n",
            "   unrelated       0.67      0.50      0.57       108\n",
            "\n",
            "    accuracy                           0.62       212\n",
            "   macro avg       0.63      0.62      0.61       212\n",
            "weighted avg       0.63      0.62      0.61       212\n",
            "\n",
            "[[77 27]\n",
            " [54 54]]\n",
            "Accuracy score on three class  0.75\n",
            "['jaccard_similarity_nouns', 'glove_similarity', 'kl_divergence', 'ngram_overlap']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.90      0.75      0.82       158\n",
            "   unrelated       0.51      0.76      0.61        54\n",
            "\n",
            "    accuracy                           0.75       212\n",
            "   macro avg       0.70      0.75      0.71       212\n",
            "weighted avg       0.80      0.75      0.76       212\n",
            "\n",
            "[[118  40]\n",
            " [ 13  41]]\n",
            "Accuracy score on three class  0.7405660377358491\n",
            "['jaccard_similarity_nouns', 'glove_similarity', 'kl_divergence', 'semantic_similarity']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.82      0.77      0.80       140\n",
            "   unrelated       0.60      0.68      0.64        72\n",
            "\n",
            "    accuracy                           0.74       212\n",
            "   macro avg       0.71      0.73      0.72       212\n",
            "weighted avg       0.75      0.74      0.74       212\n",
            "\n",
            "[[108  32]\n",
            " [ 23  49]]\n",
            "Accuracy score on three class  0.7735849056603774\n",
            "['jaccard_similarity_nouns', 'glove_similarity', 'kl_divergence', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.90      0.77      0.83       153\n",
            "   unrelated       0.57      0.78      0.66        59\n",
            "\n",
            "    accuracy                           0.77       212\n",
            "   macro avg       0.73      0.78      0.74       212\n",
            "weighted avg       0.81      0.77      0.78       212\n",
            "\n",
            "[[118  35]\n",
            " [ 13  46]]\n",
            "Accuracy score on three class  0.6226415094339622\n",
            "['jaccard_similarity_nouns', 'glove_similarity', 'ngram_overlap', 'semantic_similarity']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.59      0.75      0.66       103\n",
            "   unrelated       0.68      0.50      0.58       109\n",
            "\n",
            "    accuracy                           0.62       212\n",
            "   macro avg       0.63      0.63      0.62       212\n",
            "weighted avg       0.63      0.62      0.62       212\n",
            "\n",
            "[[77 26]\n",
            " [54 55]]\n",
            "Accuracy score on three class  0.7830188679245284\n",
            "['jaccard_similarity_nouns', 'glove_similarity', 'ngram_overlap', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.82      0.82      0.82       131\n",
            "   unrelated       0.72      0.72      0.72        81\n",
            "\n",
            "    accuracy                           0.78       212\n",
            "   macro avg       0.77      0.77      0.77       212\n",
            "weighted avg       0.78      0.78      0.78       212\n",
            "\n",
            "[[108  23]\n",
            " [ 23  58]]\n",
            "Accuracy score on three class  0.5801886792452831\n",
            "['jaccard_similarity_nouns', 'glove_similarity', 'semantic_similarity', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.44      0.78      0.57        74\n",
            "   unrelated       0.80      0.47      0.59       138\n",
            "\n",
            "    accuracy                           0.58       212\n",
            "   macro avg       0.62      0.63      0.58       212\n",
            "weighted avg       0.68      0.58      0.58       212\n",
            "\n",
            "[[58 16]\n",
            " [73 65]]\n",
            "Accuracy score on three class  0.6886792452830188\n",
            "['jaccard_similarity_nouns', 'kl_divergence', 'ngram_overlap', 'semantic_similarity']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.82      0.72      0.77       151\n",
            "   unrelated       0.47      0.62      0.54        61\n",
            "\n",
            "    accuracy                           0.69       212\n",
            "   macro avg       0.65      0.67      0.65       212\n",
            "weighted avg       0.72      0.69      0.70       212\n",
            "\n",
            "[[108  43]\n",
            " [ 23  38]]\n",
            "Accuracy score on three class  0.75\n",
            "['jaccard_similarity_nouns', 'kl_divergence', 'ngram_overlap', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.89      0.75      0.82       156\n",
            "   unrelated       0.52      0.75      0.61        56\n",
            "\n",
            "    accuracy                           0.75       212\n",
            "   macro avg       0.71      0.75      0.71       212\n",
            "weighted avg       0.79      0.75      0.76       212\n",
            "\n",
            "[[117  39]\n",
            " [ 14  42]]\n",
            "Accuracy score on three class  0.7311320754716981\n",
            "['jaccard_similarity_nouns', 'kl_divergence', 'semantic_similarity', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.80      0.77      0.79       136\n",
            "   unrelated       0.62      0.66      0.64        76\n",
            "\n",
            "    accuracy                           0.73       212\n",
            "   macro avg       0.71      0.71      0.71       212\n",
            "weighted avg       0.74      0.73      0.73       212\n",
            "\n",
            "[[105  31]\n",
            " [ 26  50]]\n",
            "Accuracy score on three class  0.6132075471698113\n",
            "['jaccard_similarity_nouns', 'ngram_overlap', 'semantic_similarity', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.53      0.77      0.63        91\n",
            "   unrelated       0.74      0.50      0.59       121\n",
            "\n",
            "    accuracy                           0.61       212\n",
            "   macro avg       0.64      0.63      0.61       212\n",
            "weighted avg       0.65      0.61      0.61       212\n",
            "\n",
            "[[70 21]\n",
            " [61 60]]\n",
            "Accuracy score on three class  0.4481132075471698\n",
            "['glove_similarity', 'kl_divergence', 'ngram_overlap', 'semantic_similarity']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.34      0.59      0.43        76\n",
            "   unrelated       0.62      0.37      0.46       136\n",
            "\n",
            "    accuracy                           0.45       212\n",
            "   macro avg       0.48      0.48      0.45       212\n",
            "weighted avg       0.52      0.45      0.45       212\n",
            "\n",
            "[[45 31]\n",
            " [86 50]]\n",
            "Accuracy score on three class  0.5660377358490566\n",
            "['glove_similarity', 'kl_divergence', 'ngram_overlap', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.60      0.67      0.63       117\n",
            "   unrelated       0.52      0.44      0.48        95\n",
            "\n",
            "    accuracy                           0.57       212\n",
            "   macro avg       0.56      0.55      0.55       212\n",
            "weighted avg       0.56      0.57      0.56       212\n",
            "\n",
            "[[78 39]\n",
            " [53 42]]\n",
            "Accuracy score on three class  0.49528301886792453\n",
            "['glove_similarity', 'kl_divergence', 'semantic_similarity', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.36      0.67      0.47        70\n",
            "   unrelated       0.72      0.41      0.52       142\n",
            "\n",
            "    accuracy                           0.50       212\n",
            "   macro avg       0.54      0.54      0.49       212\n",
            "weighted avg       0.60      0.50      0.50       212\n",
            "\n",
            "[[47 23]\n",
            " [84 58]]\n",
            "Accuracy score on three class  0.45754716981132076\n",
            "['glove_similarity', 'ngram_overlap', 'semantic_similarity', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.26      0.65      0.37        52\n",
            "   unrelated       0.78      0.39      0.52       160\n",
            "\n",
            "    accuracy                           0.46       212\n",
            "   macro avg       0.52      0.52      0.45       212\n",
            "weighted avg       0.65      0.46      0.49       212\n",
            "\n",
            "[[34 18]\n",
            " [97 63]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy score on three class  0.419811320754717\n",
            "['kl_divergence', 'ngram_overlap', 'semantic_similarity', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.34      0.55      0.42        80\n",
            "   unrelated       0.56      0.34      0.42       132\n",
            "\n",
            "    accuracy                           0.42       212\n",
            "   macro avg       0.45      0.45      0.42       212\n",
            "weighted avg       0.47      0.42      0.42       212\n",
            "\n",
            "[[44 36]\n",
            " [87 45]]\n",
            "Accuracy score on three class  0.7311320754716981\n",
            "['jaccard_similarity', 'jaccard_similarity_nouns', 'glove_similarity', 'kl_divergence', 'ngram_overlap']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.92      0.72      0.81       168\n",
            "   unrelated       0.42      0.77      0.54        44\n",
            "\n",
            "    accuracy                           0.73       212\n",
            "   macro avg       0.67      0.75      0.68       212\n",
            "weighted avg       0.82      0.73      0.75       212\n",
            "\n",
            "[[121  47]\n",
            " [ 10  34]]\n",
            "Accuracy score on three class  0.7405660377358491\n",
            "['jaccard_similarity', 'jaccard_similarity_nouns', 'glove_similarity', 'kl_divergence', 'semantic_similarity']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.88      0.75      0.81       154\n",
            "   unrelated       0.52      0.72      0.60        58\n",
            "\n",
            "    accuracy                           0.74       212\n",
            "   macro avg       0.70      0.74      0.71       212\n",
            "weighted avg       0.78      0.74      0.75       212\n",
            "\n",
            "[[115  39]\n",
            " [ 16  42]]\n",
            "Accuracy score on three class  0.7405660377358491\n",
            "['jaccard_similarity', 'jaccard_similarity_nouns', 'glove_similarity', 'kl_divergence', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.91      0.73      0.81       162\n",
            "   unrelated       0.47      0.76      0.58        50\n",
            "\n",
            "    accuracy                           0.74       212\n",
            "   macro avg       0.69      0.75      0.70       212\n",
            "weighted avg       0.80      0.74      0.76       212\n",
            "\n",
            "[[119  43]\n",
            " [ 12  38]]\n",
            "Accuracy score on three class  0.6320754716981132\n",
            "['jaccard_similarity', 'jaccard_similarity_nouns', 'glove_similarity', 'ngram_overlap', 'semantic_similarity']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.65      0.73      0.69       117\n",
            "   unrelated       0.60      0.52      0.56        95\n",
            "\n",
            "    accuracy                           0.63       212\n",
            "   macro avg       0.63      0.62      0.62       212\n",
            "weighted avg       0.63      0.63      0.63       212\n",
            "\n",
            "[[85 32]\n",
            " [46 49]]\n",
            "Accuracy score on three class  0.7641509433962265\n",
            "['jaccard_similarity', 'jaccard_similarity_nouns', 'glove_similarity', 'ngram_overlap', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.90      0.76      0.83       155\n",
            "   unrelated       0.54      0.77      0.64        57\n",
            "\n",
            "    accuracy                           0.76       212\n",
            "   macro avg       0.72      0.77      0.73       212\n",
            "weighted avg       0.80      0.76      0.77       212\n",
            "\n",
            "[[118  37]\n",
            " [ 13  44]]\n",
            "Accuracy score on three class  0.6462264150943396\n",
            "['jaccard_similarity', 'jaccard_similarity_nouns', 'glove_similarity', 'semantic_similarity', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.59      0.79      0.67        98\n",
            "   unrelated       0.74      0.53      0.62       114\n",
            "\n",
            "    accuracy                           0.65       212\n",
            "   macro avg       0.66      0.66      0.64       212\n",
            "weighted avg       0.67      0.65      0.64       212\n",
            "\n",
            "[[77 21]\n",
            " [54 60]]\n",
            "Accuracy score on three class  0.6886792452830188\n",
            "['jaccard_similarity', 'jaccard_similarity_nouns', 'kl_divergence', 'ngram_overlap', 'semantic_similarity']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.84      0.71      0.77       155\n",
            "   unrelated       0.44      0.63      0.52        57\n",
            "\n",
            "    accuracy                           0.69       212\n",
            "   macro avg       0.64      0.67      0.65       212\n",
            "weighted avg       0.73      0.69      0.70       212\n",
            "\n",
            "[[110  45]\n",
            " [ 21  36]]\n",
            "Accuracy score on three class  0.7452830188679245\n",
            "['jaccard_similarity', 'jaccard_similarity_nouns', 'kl_divergence', 'ngram_overlap', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.92      0.73      0.82       165\n",
            "   unrelated       0.46      0.79      0.58        47\n",
            "\n",
            "    accuracy                           0.75       212\n",
            "   macro avg       0.69      0.76      0.70       212\n",
            "weighted avg       0.82      0.75      0.76       212\n",
            "\n",
            "[[121  44]\n",
            " [ 10  37]]\n",
            "Accuracy score on three class  0.7358490566037735\n",
            "['jaccard_similarity', 'jaccard_similarity_nouns', 'kl_divergence', 'semantic_similarity', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.85      0.75      0.80       149\n",
            "   unrelated       0.54      0.70      0.61        63\n",
            "\n",
            "    accuracy                           0.74       212\n",
            "   macro avg       0.70      0.73      0.71       212\n",
            "weighted avg       0.76      0.74      0.74       212\n",
            "\n",
            "[[112  37]\n",
            " [ 19  44]]\n",
            "Accuracy score on three class  0.6179245283018868\n",
            "['jaccard_similarity', 'jaccard_similarity_nouns', 'ngram_overlap', 'semantic_similarity', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.63      0.72      0.67       116\n",
            "   unrelated       0.59      0.50      0.54        96\n",
            "\n",
            "    accuracy                           0.62       212\n",
            "   macro avg       0.61      0.61      0.61       212\n",
            "weighted avg       0.62      0.62      0.61       212\n",
            "\n",
            "[[83 33]\n",
            " [48 48]]\n",
            "Accuracy score on three class  0.6839622641509434\n",
            "['jaccard_similarity', 'glove_similarity', 'kl_divergence', 'ngram_overlap', 'semantic_similarity']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.82      0.71      0.76       150\n",
            "   unrelated       0.47      0.61      0.53        62\n",
            "\n",
            "    accuracy                           0.68       212\n",
            "   macro avg       0.64      0.66      0.65       212\n",
            "weighted avg       0.72      0.68      0.69       212\n",
            "\n",
            "[[107  43]\n",
            " [ 24  38]]\n",
            "Accuracy score on three class  0.7358490566037735\n",
            "['jaccard_similarity', 'glove_similarity', 'kl_divergence', 'ngram_overlap', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.92      0.73      0.81       165\n",
            "   unrelated       0.44      0.77      0.56        47\n",
            "\n",
            "    accuracy                           0.74       212\n",
            "   macro avg       0.68      0.75      0.69       212\n",
            "weighted avg       0.81      0.74      0.76       212\n",
            "\n",
            "[[120  45]\n",
            " [ 11  36]]\n",
            "Accuracy score on three class  0.7216981132075472\n",
            "['jaccard_similarity', 'glove_similarity', 'kl_divergence', 'semantic_similarity', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.83      0.75      0.79       146\n",
            "   unrelated       0.54      0.67      0.60        66\n",
            "\n",
            "    accuracy                           0.72       212\n",
            "   macro avg       0.69      0.71      0.69       212\n",
            "weighted avg       0.74      0.72      0.73       212\n",
            "\n",
            "[[109  37]\n",
            " [ 22  44]]\n",
            "Accuracy score on three class  0.589622641509434\n",
            "['jaccard_similarity', 'glove_similarity', 'ngram_overlap', 'semantic_similarity', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.55      0.72      0.62       100\n",
            "   unrelated       0.65      0.47      0.55       112\n",
            "\n",
            "    accuracy                           0.59       212\n",
            "   macro avg       0.60      0.60      0.59       212\n",
            "weighted avg       0.60      0.59      0.58       212\n",
            "\n",
            "[[72 28]\n",
            " [59 53]]\n",
            "Accuracy score on three class  0.6650943396226415\n",
            "['jaccard_similarity', 'kl_divergence', 'ngram_overlap', 'semantic_similarity', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.79      0.70      0.75       148\n",
            "   unrelated       0.46      0.58      0.51        64\n",
            "\n",
            "    accuracy                           0.67       212\n",
            "   macro avg       0.63      0.64      0.63       212\n",
            "weighted avg       0.69      0.67      0.67       212\n",
            "\n",
            "[[104  44]\n",
            " [ 27  37]]\n",
            "Accuracy score on three class  0.7122641509433962\n",
            "['jaccard_similarity_nouns', 'glove_similarity', 'kl_divergence', 'ngram_overlap', 'semantic_similarity']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.83      0.74      0.78       148\n",
            "   unrelated       0.52      0.66      0.58        64\n",
            "\n",
            "    accuracy                           0.71       212\n",
            "   macro avg       0.68      0.70      0.68       212\n",
            "weighted avg       0.74      0.71      0.72       212\n",
            "\n",
            "[[109  39]\n",
            " [ 22  42]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy score on three class  0.7688679245283019\n",
            "['jaccard_similarity_nouns', 'glove_similarity', 'kl_divergence', 'ngram_overlap', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.89      0.77      0.83       150\n",
            "   unrelated       0.58      0.76      0.66        62\n",
            "\n",
            "    accuracy                           0.77       212\n",
            "   macro avg       0.73      0.77      0.74       212\n",
            "weighted avg       0.80      0.77      0.78       212\n",
            "\n",
            "[[116  34]\n",
            " [ 15  47]]\n",
            "Accuracy score on three class  0.7216981132075472\n",
            "['jaccard_similarity_nouns', 'glove_similarity', 'kl_divergence', 'semantic_similarity', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.79      0.76      0.78       136\n",
            "   unrelated       0.60      0.64      0.62        76\n",
            "\n",
            "    accuracy                           0.72       212\n",
            "   macro avg       0.70      0.70      0.70       212\n",
            "weighted avg       0.73      0.72      0.72       212\n",
            "\n",
            "[[104  32]\n",
            " [ 27  49]]\n",
            "Accuracy score on three class  0.6320754716981132\n",
            "['jaccard_similarity_nouns', 'glove_similarity', 'ngram_overlap', 'semantic_similarity', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.58      0.77      0.66        99\n",
            "   unrelated       0.72      0.51      0.60       113\n",
            "\n",
            "    accuracy                           0.63       212\n",
            "   macro avg       0.65      0.64      0.63       212\n",
            "weighted avg       0.65      0.63      0.63       212\n",
            "\n",
            "[[76 23]\n",
            " [55 58]]\n",
            "Accuracy score on three class  0.6981132075471698\n",
            "['jaccard_similarity_nouns', 'kl_divergence', 'ngram_overlap', 'semantic_similarity', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.80      0.73      0.77       143\n",
            "   unrelated       0.53      0.62      0.57        69\n",
            "\n",
            "    accuracy                           0.70       212\n",
            "   macro avg       0.67      0.68      0.67       212\n",
            "weighted avg       0.71      0.70      0.70       212\n",
            "\n",
            "[[105  38]\n",
            " [ 26  43]]\n",
            "Accuracy score on three class  0.4669811320754717\n",
            "['glove_similarity', 'kl_divergence', 'ngram_overlap', 'semantic_similarity', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.35      0.62      0.45        74\n",
            "   unrelated       0.65      0.38      0.48       138\n",
            "\n",
            "    accuracy                           0.47       212\n",
            "   macro avg       0.50      0.50      0.47       212\n",
            "weighted avg       0.55      0.47      0.47       212\n",
            "\n",
            "[[46 28]\n",
            " [85 53]]\n",
            "Accuracy score on three class  0.6886792452830188\n",
            "['jaccard_similarity', 'jaccard_similarity_nouns', 'glove_similarity', 'kl_divergence', 'ngram_overlap', 'semantic_similarity']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.85      0.71      0.77       157\n",
            "   unrelated       0.43      0.64      0.51        55\n",
            "\n",
            "    accuracy                           0.69       212\n",
            "   macro avg       0.64      0.67      0.64       212\n",
            "weighted avg       0.74      0.69      0.70       212\n",
            "\n",
            "[[111  46]\n",
            " [ 20  35]]\n",
            "Accuracy score on three class  0.7547169811320755\n",
            "['jaccard_similarity', 'jaccard_similarity_nouns', 'glove_similarity', 'kl_divergence', 'ngram_overlap', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.92      0.75      0.82       161\n",
            "   unrelated       0.49      0.78      0.61        51\n",
            "\n",
            "    accuracy                           0.75       212\n",
            "   macro avg       0.70      0.76      0.71       212\n",
            "weighted avg       0.81      0.75      0.77       212\n",
            "\n",
            "[[120  41]\n",
            " [ 11  40]]\n",
            "Accuracy score on three class  0.7452830188679245\n",
            "['jaccard_similarity', 'jaccard_similarity_nouns', 'glove_similarity', 'kl_divergence', 'semantic_similarity', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.87      0.75      0.81       151\n",
            "   unrelated       0.54      0.72      0.62        61\n",
            "\n",
            "    accuracy                           0.75       212\n",
            "   macro avg       0.71      0.74      0.71       212\n",
            "weighted avg       0.78      0.75      0.75       212\n",
            "\n",
            "[[114  37]\n",
            " [ 17  44]]\n",
            "Accuracy score on three class  0.6273584905660378\n",
            "['jaccard_similarity', 'jaccard_similarity_nouns', 'glove_similarity', 'ngram_overlap', 'semantic_similarity', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.63      0.73      0.67       112\n",
            "   unrelated       0.63      0.51      0.56       100\n",
            "\n",
            "    accuracy                           0.63       212\n",
            "   macro avg       0.63      0.62      0.62       212\n",
            "weighted avg       0.63      0.63      0.62       212\n",
            "\n",
            "[[82 30]\n",
            " [49 51]]\n",
            "Accuracy score on three class  0.7169811320754716\n",
            "['jaccard_similarity', 'jaccard_similarity_nouns', 'kl_divergence', 'ngram_overlap', 'semantic_similarity', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.85      0.74      0.79       151\n",
            "   unrelated       0.51      0.67      0.58        61\n",
            "\n",
            "    accuracy                           0.72       212\n",
            "   macro avg       0.68      0.70      0.68       212\n",
            "weighted avg       0.75      0.72      0.73       212\n",
            "\n",
            "[[111  40]\n",
            " [ 20  41]]\n",
            "Accuracy score on three class  0.6981132075471698\n",
            "['jaccard_similarity', 'glove_similarity', 'kl_divergence', 'ngram_overlap', 'semantic_similarity', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.82      0.73      0.77       147\n",
            "   unrelated       0.51      0.63      0.56        65\n",
            "\n",
            "    accuracy                           0.70       212\n",
            "   macro avg       0.66      0.68      0.67       212\n",
            "weighted avg       0.72      0.70      0.71       212\n",
            "\n",
            "[[107  40]\n",
            " [ 24  41]]\n",
            "Accuracy score on three class  0.6933962264150944\n",
            "['jaccard_similarity_nouns', 'glove_similarity', 'kl_divergence', 'ngram_overlap', 'semantic_similarity', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.78      0.74      0.76       138\n",
            "   unrelated       0.56      0.61      0.58        74\n",
            "\n",
            "    accuracy                           0.69       212\n",
            "   macro avg       0.67      0.67      0.67       212\n",
            "weighted avg       0.70      0.69      0.70       212\n",
            "\n",
            "[[102  36]\n",
            " [ 29  45]]\n",
            "Accuracy score on three class  0.7264150943396226\n",
            "['jaccard_similarity', 'jaccard_similarity_nouns', 'glove_similarity', 'kl_divergence', 'ngram_overlap', 'semantic_similarity', 'LDA_Score']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.85      0.74      0.79       151\n",
            "   unrelated       0.52      0.69      0.59        61\n",
            "\n",
            "    accuracy                           0.73       212\n",
            "   macro avg       0.69      0.72      0.69       212\n",
            "weighted avg       0.76      0.73      0.74       212\n",
            "\n",
            "[[112  39]\n",
            " [ 19  42]]\n",
            "max accuracy 0.8066037735849056\n",
            "[0.7735849056603774, 0.8018867924528302, 0.5707547169811321, 0.6981132075471698, 0.38207547169811323, 0.3867924528301887, 0.37264150943396224, 0.7311320754716981, 0.7264150943396226, 0.75, 0.7594339622641509, 0.6132075471698113, 0.7688679245283019, 0.7924528301886793, 0.7641509433962265, 0.7924528301886793, 0.5943396226415094, 0.7877358490566038, 0.5943396226415094, 0.5660377358490566, 0.42924528301886794, 0.5188679245283019, 0.6650943396226415, 0.4669811320754717, 0.6698113207547169, 0.38207547169811323, 0.37264150943396224, 0.3915094339622642, 0.75, 0.7452830188679245, 0.7547169811320755, 0.6839622641509434, 0.7641509433962265, 0.7452830188679245, 0.7264150943396226, 0.6273584905660378, 0.7122641509433962, 0.7075471698113207, 0.7311320754716981, 0.7405660377358491, 0.589622641509434, 0.7594339622641509, 0.5754716981132075, 0.7735849056603774, 0.8066037735849056, 0.6084905660377359, 0.7877358490566038, 0.7452830188679245, 0.7358490566037735, 0.7688679245283019, 0.6037735849056604, 0.75, 0.5566037735849056, 0.5707547169811321, 0.5, 0.5943396226415094, 0.4481132075471698, 0.5283018867924528, 0.39622641509433965, 0.39622641509433965, 0.6367924528301887, 0.4339622641509434, 0.38207547169811323, 0.75, 0.7547169811320755, 0.660377358490566, 0.75, 0.7169811320754716, 0.75, 0.75, 0.6462264150943396, 0.7735849056603774, 0.660377358490566, 0.7075471698113207, 0.7311320754716981, 0.7358490566037735, 0.6273584905660378, 0.7547169811320755, 0.6132075471698113, 0.6792452830188679, 0.7264150943396226, 0.7216981132075472, 0.6179245283018868, 0.75, 0.7405660377358491, 0.7735849056603774, 0.6226415094339622, 0.7830188679245284, 0.5801886792452831, 0.6886792452830188, 0.75, 0.7311320754716981, 0.6132075471698113, 0.4481132075471698, 0.5660377358490566, 0.49528301886792453, 0.45754716981132076, 0.419811320754717, 0.7311320754716981, 0.7405660377358491, 0.7405660377358491, 0.6320754716981132, 0.7641509433962265, 0.6462264150943396, 0.6886792452830188, 0.7452830188679245, 0.7358490566037735, 0.6179245283018868, 0.6839622641509434, 0.7358490566037735, 0.7216981132075472, 0.589622641509434, 0.6650943396226415, 0.7122641509433962, 0.7688679245283019, 0.7216981132075472, 0.6320754716981132, 0.6981132075471698, 0.4669811320754717, 0.6886792452830188, 0.7547169811320755, 0.7452830188679245, 0.6273584905660378, 0.7169811320754716, 0.6981132075471698, 0.6933962264150944, 0.7264150943396226]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fN80Vdd72c59",
        "outputId": "8bc99fb5-d587-4324-912a-4246f031e726"
      },
      "source": [
        "['jaccard_similarity_nouns', 'glove_similarity']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['jaccard_similarity_nouns', 'glove_similarity']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oT4hKFWo2c59"
      },
      "source": [
        "['jaccard_similarity_nouns', 'glove_similarity', 'ngram_overlap']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KzBxTNh2c59"
      },
      "source": [
        "# import libraries\n",
        "    \n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from nltk.corpus import stopwords\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ICzjVSF2c5-"
      },
      "source": [
        " #xtrain,xtest,ytrain,ytest = train_test_split(x,y,test_size=0.1, random_state = 101)\n",
        "xtrain3 = train[['jaccard_similarity_nouns', 'glove_similarity', 'ngram_overlap']]\n",
        "ytrain3 = train['stance_base'] \n",
        "xtest3 = test[['jaccard_similarity_nouns', 'glove_similarity', 'ngram_overlap']]\n",
        "ytest3 = test[\"stance_base\"]\n",
        "rg = RandomForestClassifier(n_estimators=100,n_jobs=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KunFAvk82c5-"
      },
      "source": [
        "xtrain3 = xtrain3.values.reshape(-1,3)\n",
        "xtest3 = xtest3.values.reshape(-1,3)\n",
        "\n",
        "rg.fit(xtrain3,ytrain3)\n",
        "ypred2 = rg.predict(xtest3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgZKVtcS2c5_",
        "outputId": "5d554072-c8a4-4d94-c425-808549e73e79"
      },
      "source": [
        "train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(75385, 18)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRs6W0fL2c5_",
        "outputId": "dc23ec27-513b-467e-b634-5bd7c9e1bcf7"
      },
      "source": [
        "test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(212, 18)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTEW5ePP2c5_",
        "outputId": "eccacd0f-5ea8-4535-d2ba-bc72d9c75e0d"
      },
      "source": [
        "\n",
        "print('Accuracy score on two class related and unrelated class ',accuracy_score(ypred2,ytest3))\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(classification_report(ypred2,ytest3))\n",
        "print(confusion_matrix(ypred2,ytest3))3\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score on two class related and unrelated class  0.8113207547169812\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     related       0.89      0.82      0.85       141\n",
            "   unrelated       0.69      0.79      0.74        71\n",
            "\n",
            "    accuracy                           0.81       212\n",
            "   macro avg       0.79      0.81      0.79       212\n",
            "weighted avg       0.82      0.81      0.81       212\n",
            "\n",
            "[[116  25]\n",
            " [ 15  56]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtNAqBLf5Gd7"
      },
      "source": [
        "**Results :  The best combination of features turned out to be Jaccard nouns similarity, GloVe similarity and N-grams. These 3 features gave 81% accuracy using Random forest classifier.**"
      ]
    }
  ]
}